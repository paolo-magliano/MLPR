\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Lab 2: Dataset}{1}{section.1}\protected@file@percent }
\newlabel{sec:dataset}{{1}{1}{Lab 2: Dataset}{section.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The figure shows histograms of the projected data on each feature. The scatter plot shows the correlation between the two features.}}{1}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:dataset}{{1}{1}{The figure shows histograms of the projected data on each feature. The scatter plot shows the correlation between the two features}{figure.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Lab 3: PCA and LDA}{2}{section.2}\protected@file@percent }
\newlabel{sec:pca_lda}{{2}{2}{Lab 3: PCA and LDA}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Dimensionality Reduction}{2}{subsection.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The figure shows the results of PCA on the dataset. The histograms show data distribution on each principal component. The top left one represents the first principal component, the bottom right is the last one. }}{2}{figure.caption.2}\protected@file@percent }
\newlabel{fig:dataset_pca}{{2}{2}{The figure shows the results of PCA on the dataset. The histograms show data distribution on each principal component. The top left one represents the first principal component, the bottom right is the last one}{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Classification}{2}{subsection.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The figure shows the results of LDA on the dataset. The histogram shows data distribution on the only linear discriminant found.}}{3}{figure.caption.3}\protected@file@percent }
\newlabel{fig:dataset_lda}{{3}{3}{The figure shows the results of LDA on the dataset. The histogram shows data distribution on the only linear discriminant found}{figure.caption.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Performance metrics for LDA models with various dimensionality reduction techniques.}}{3}{table.caption.4}\protected@file@percent }
\newlabel{tab:lda_performance}{{1}{3}{Performance metrics for LDA models with various dimensionality reduction techniques}{table.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Lab 4: Multivariate Gaussian density}{4}{section.3}\protected@file@percent }
\newlabel{sec:gaussian_density}{{3}{4}{Lab 4: Multivariate Gaussian density}{section.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The figure shows the histograms of the dataset and the Gaussian density function that best fits each feature.}}{4}{figure.caption.5}\protected@file@percent }
\newlabel{fig:dataset_gaussian}{{4}{4}{The figure shows the histograms of the dataset and the Gaussian density function that best fits each feature}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Lab 5: Multivariate Gaussian Model}{4}{section.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Performance metrics for various MVG models without dimensionality reduction.}}{4}{table.caption.6}\protected@file@percent }
\newlabel{tab:mvg_performance}{{2}{4}{Performance metrics for various MVG models without dimensionality reduction}{table.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The figure shows the histograms of the dataset and the Gaussian density function with tied covariance matrix for each feature.}}{5}{figure.caption.7}\protected@file@percent }
\newlabel{fig:dataset_gaussian_tied}{{5}{5}{The figure shows the histograms of the dataset and the Gaussian density function with tied covariance matrix for each feature}{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Correlation Analysis}{5}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Assumption Analysis}{5}{subsection.4.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Performance metrics for various MVG models with only the first 4 features.}}{5}{table.caption.9}\protected@file@percent }
\newlabel{tab:mvg_performance_4}{{3}{5}{Performance metrics for various MVG models with only the first 4 features}{table.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The figure shows the Pearson correlation coefficient between the features for each class. Correlated features are close to 1 or -1.}}{6}{figure.caption.8}\protected@file@percent }
\newlabel{fig:dataset_person}{{6}{6}{The figure shows the Pearson correlation coefficient between the features for each class. Correlated features are close to 1 or -1}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Mean and Variance of Features Analysis}{6}{subsection.4.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Performance metrics for various MVG models with only the first 2 features.}}{6}{table.caption.10}\protected@file@percent }
\newlabel{tab:mvg_performance_12}{{4}{6}{Performance metrics for various MVG models with only the first 2 features}{table.caption.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Performance metrics for various MVG models with only the 3 and 4 features.}}{6}{table.caption.11}\protected@file@percent }
\newlabel{tab:mvg_performance_34}{{5}{6}{Performance metrics for various MVG models with only the 3 and 4 features}{table.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Dimensionality reduction}{7}{subsection.4.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Performance metrics for various MVG models with PCA as a preprocessing technique.}}{7}{table.caption.12}\protected@file@percent }
\newlabel{tab:mvg_performance_pca}{{6}{7}{Performance metrics for various MVG models with PCA as a preprocessing technique}{table.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Lab 7: Model Evaluation}{7}{section.5}\protected@file@percent }
\newlabel{sec:model_evaluation}{{5}{7}{Lab 7: Model Evaluation}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Different Application}{7}{subsection.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The figure shows the confusion matrix for the different application setups for the MVG model.}}{8}{figure.caption.13}\protected@file@percent }
\newlabel{fig:confusion_matrix}{{7}{8}{The figure shows the confusion matrix for the different application setups for the MVG model}{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Application Evaluation}{8}{subsection.5.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Performance metrics for various MVG models with (0.1, 1, 1) application setup.}}{8}{table.caption.14}\protected@file@percent }
\newlabel{tab:mvg_performance_1_1_1}{{7}{8}{Performance metrics for various MVG models with (0.1, 1, 1) application setup}{table.caption.14}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Performance metrics for various MVG models with (0.9, 1, 1) application setup.}}{8}{table.caption.15}\protected@file@percent }
\newlabel{tab:mvg_performance_9_1_1}{{8}{8}{Performance metrics for various MVG models with (0.9, 1, 1) application setup}{table.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Bayes Error Plot}{9}{subsection.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The figure shows the Bayes error plot for the MVG models with PCA 6 for (0.1, 1, 1) application setup.}}{9}{figure.caption.16}\protected@file@percent }
\newlabel{fig:mvg_bayes_error}{{8}{9}{The figure shows the Bayes error plot for the MVG models with PCA 6 for (0.1, 1, 1) application setup}{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Lab 8: Logistic Regression}{9}{section.6}\protected@file@percent }
\newlabel{sec:logistic_regression}{{6}{9}{Lab 8: Logistic Regression}{section.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Regularization}{9}{subsection.6.1}\protected@file@percent }
\newlabel{fig:lr_lambda}{{9a}{10}{All dataset}{figure.caption.17}{}}
\newlabel{sub@fig:lr_lambda}{{a}{10}{All dataset}{figure.caption.17}{}}
\newlabel{fig:lr_lambda_100}{{9b}{10}{$\frac {1}{100}$ dataset}{figure.caption.17}{}}
\newlabel{sub@fig:lr_lambda_100}{{b}{10}{$\frac {1}{100}$ dataset}{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The figure shows the performance of LR models with different $\lambda $.}}{10}{figure.caption.17}\protected@file@percent }
\newlabel{fig:lr_lambda_prior}{{10a}{10}{All dataset}{figure.caption.18}{}}
\newlabel{sub@fig:lr_lambda_prior}{{a}{10}{All dataset}{figure.caption.18}{}}
\newlabel{fig:lr_lambda_100_prior}{{10b}{10}{$\frac {1}{100}$ dataset}{figure.caption.18}{}}
\newlabel{sub@fig:lr_lambda_100_prior}{{b}{10}{$\frac {1}{100}$ dataset}{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The figure shows the performance of LR models with prior-weighted models.}}{10}{figure.caption.18}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Expanded Feature Space}{10}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Affine Transformation}{10}{subsection.6.3}\protected@file@percent }
\newlabel{fig:lr_lambda_quadratic}{{11a}{11}{The figure shows the performance of LR models with expanded feature space}{figure.caption.19}{}}
\newlabel{sub@fig:lr_lambda_quadratic}{{a}{11}{The figure shows the performance of LR models with expanded feature space}{figure.caption.19}{}}
\newlabel{fig:lr_lambda_centered}{{11b}{11}{The figure shows the performance of LR models with centered features}{figure.caption.19}{}}
\newlabel{sub@fig:lr_lambda_centered}{{b}{11}{The figure shows the performance of LR models with centered features}{figure.caption.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Lab 9: Support Vector Machines}{11}{section.7}\protected@file@percent }
\newlabel{sec:svm}{{7}{11}{Lab 9: Support Vector Machines}{section.7}{}}
\newlabel{fig:svm_C}{{12a}{11}{The figure shows the performance of SVM models with different C}{figure.caption.20}{}}
\newlabel{sub@fig:svm_C}{{a}{11}{The figure shows the performance of SVM models with different C}{figure.caption.20}{}}
\newlabel{fig:svm_C_centered}{{12b}{11}{The figure shows the performance of SVM model with centered dataset}{figure.caption.20}{}}
\newlabel{sub@fig:svm_C_centered}{{b}{11}{The figure shows the performance of SVM model with centered dataset}{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Non-linear SVM}{12}{subsection.7.1}\protected@file@percent }
\newlabel{fig:svm_C_poly}{{13a}{12}{The figure shows the performance of SVM models with polynomial kernel}{figure.caption.21}{}}
\newlabel{sub@fig:svm_C_poly}{{a}{12}{The figure shows the performance of SVM models with polynomial kernel}{figure.caption.21}{}}
\newlabel{fig:svm_C_rbf}{{13b}{12}{The figure shows the performance of SVM models with RBF kernel}{figure.caption.21}{}}
\newlabel{sub@fig:svm_C_rbf}{{b}{12}{The figure shows the performance of SVM models with RBF kernel}{figure.caption.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Lab 10: Gaussian Mixture Models}{12}{section.8}\protected@file@percent }
\newlabel{sec:gmm}{{8}{12}{Lab 10: Gaussian Mixture Models}{section.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces The figure shows the performance of GMM models with different M and covariance matrix.}}{12}{figure.caption.22}\protected@file@percent }
\newlabel{fig:gmm_M}{{14}{12}{The figure shows the performance of GMM models with different M and covariance matrix}{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces The figure shows the histograms of the dataset and the Gaussian Mixture Model that best fits the data.}}{13}{figure.caption.23}\protected@file@percent }
\newlabel{fig:dataset_gmm}{{15}{13}{The figure shows the histograms of the dataset and the Gaussian Mixture Model that best fits the data}{figure.caption.23}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Lab 11: Calibration}{13}{section.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Model comparison}{13}{subsection.9.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Performance metrics for the best models with application setup (0.1, 1, 1).}}{13}{table.caption.25}\protected@file@percent }
\newlabel{tab:models_performance}{{9}{13}{Performance metrics for the best models with application setup (0.1, 1, 1)}{table.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces The figure shows the histograms of the dataset and the Diagonal Gaussian Mixture Model that best fits the data.}}{14}{figure.caption.24}\protected@file@percent }
\newlabel{fig:dataset_gmm_diagonal}{{16}{14}{The figure shows the histograms of the dataset and the Diagonal Gaussian Mixture Model that best fits the data}{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces The figure shows the Bayes error plot for the best models with application setup (0.1, 1, 1).}}{14}{figure.caption.26}\protected@file@percent }
\newlabel{fig:models_bayes_error}{{17}{14}{The figure shows the Bayes error plot for the best models with application setup (0.1, 1, 1)}{figure.caption.26}{}}
\gdef \@abspage@last{14}
